SLURM_JOB_ID: 64140087
SLURM_JOB_USER: vsc37097
SLURM_JOB_ACCOUNT: lp-emedia
SLURM_JOB_NAME: project_h100_10.slurm
SLURM_CLUSTER_NAME: wice
SLURM_JOB_PARTITION: gpu_h100
SLURM_NNODES: 1
SLURM_NODELIST: s16g18
SLURM_JOB_CPUS_PER_NODE: 16
SLURM_JOB_GPUS: 1,2
Date: Tue Mar 25 17:18:50 CET 2025
Walltime: 00-08:00:00
========================================================================
W0325 17:19:06.703000 1231971 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] 
W0325 17:19:06.703000 1231971 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
W0325 17:19:06.703000 1231971 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0325 17:19:06.703000 1231971 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
[Rank 0] Using device: cuda:0
Training started at: 2025-03-25 17:19:19.689764
s16g18:1232004:1232004 [0] NCCL INFO Bootstrap : Using ib0:172.23.4.216<0>
s16g18:1232004:1232004 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g18:1232004:1232004 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g18:1232004:1232004 [0] NCCL INFO NET/Plugin: Using internal network plugin.
s16g18:1232004:1232004 [0] NCCL INFO cudaDriverVersion 12000
NCCL version 2.21.5+cuda12.4
s16g18:1232004:1232117 [0] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.216<0>
s16g18:1232004:1232117 [0] NCCL INFO Using non-device net plugin version 0
s16g18:1232004:1232117 [0] NCCL INFO Using network IB
s16g18:1232005:1232005 [1] NCCL INFO cudaDriverVersion 12000
s16g18:1232005:1232005 [1] NCCL INFO Bootstrap : Using ib0:172.23.4.216<0>
s16g18:1232005:1232005 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g18:1232005:1232005 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g18:1232005:1232005 [1] NCCL INFO NET/Plugin: Using internal network plugin.
s16g18:1232005:1232120 [1] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.216<0>
s16g18:1232005:1232120 [1] NCCL INFO Using non-device net plugin version 0
s16g18:1232005:1232120 [1] NCCL INFO Using network IB
s16g18:1232005:1232120 [1] NCCL INFO ncclCommInitRank comm 0xa8d31200 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId a6000 commId 0xbac1b60c80d79878 - Init START
s16g18:1232004:1232117 [0] NCCL INFO ncclCommInitRank comm 0x78650e00 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 46000 commId 0xbac1b60c80d79878 - Init START
s16g18:1232004:1232117 [0] NCCL INFO Setting affinity for GPU 0 to ff0000
s16g18:1232005:1232120 [1] NCCL INFO Setting affinity for GPU 1 to ff,00000000
s16g18:1232005:1232120 [1] NCCL INFO comm 0xa8d31200 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
s16g18:1232005:1232120 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1
s16g18:1232005:1232120 [1] NCCL INFO P2P Chunksize set to 524288
s16g18:1232004:1232117 [0] NCCL INFO comm 0x78650e00 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
s16g18:1232004:1232117 [0] NCCL INFO Channel 00/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 01/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 02/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 03/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 04/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 05/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 06/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Channel 07/08 :    0   1
s16g18:1232004:1232117 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1
s16g18:1232004:1232117 [0] NCCL INFO P2P Chunksize set to 524288
s16g18:1232004:1232117 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232004:1232117 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g18:1232005:1232120 [1] NCCL INFO Connected all rings
s16g18:1232004:1232117 [0] NCCL INFO Connected all rings
s16g18:1232005:1232120 [1] NCCL INFO Connected all trees
s16g18:1232004:1232117 [0] NCCL INFO Connected all trees
s16g18:1232005:1232120 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g18:1232005:1232120 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g18:1232004:1232117 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g18:1232004:1232117 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g18:1232005:1232120 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g18:1232005:1232120 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g18:1232005:1232120 [1] NCCL INFO ncclCommInitRank comm 0xa8d31200 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId a6000 commId 0xbac1b60c80d79878 - Init COMPLETE
s16g18:1232004:1232117 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g18:1232004:1232117 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g18:1232004:1232117 [0] NCCL INFO ncclCommInitRank comm 0x78650e00 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 46000 commId 0xbac1b60c80d79878 - Init COMPLETE
Training ended at: 2025-03-25 20:26:36.765826
Total training time: 3:07:17.076062
s16g18:1232005:1232123 [1] NCCL INFO [Service thread] Connection closed by localRank 1
s16g18:1232004:1232125 [0] NCCL INFO [Service thread] Connection closed by localRank 0
s16g18:1232005:1438302 [1] NCCL INFO comm 0xa8d31200 rank 1 nranks 2 cudaDev 1 busId a6000 - Abort COMPLETE
s16g18:1232004:1438303 [0] NCCL INFO comm 0x78650e00 rank 0 nranks 2 cudaDev 0 busId 46000 - Abort COMPLETE
