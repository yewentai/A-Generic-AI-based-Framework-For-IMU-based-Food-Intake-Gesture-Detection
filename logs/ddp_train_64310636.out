SLURM_JOB_ID: 64310636
SLURM_JOB_USER: vsc37097
SLURM_JOB_ACCOUNT: lp-emedia
SLURM_JOB_NAME: project_h100_3.slurm
SLURM_CLUSTER_NAME: wice
SLURM_JOB_PARTITION: gpu_h100
SLURM_NNODES: 1
SLURM_NODELIST: s16g21
SLURM_JOB_CPUS_PER_NODE: 16
SLURM_JOB_GPUS: 0,2
Date: Thu Apr 10 05:55:29 CEST 2025
Walltime: 00-16:00:00
========================================================================
W0410 05:55:44.415000 4117978 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] 
W0410 05:55:44.415000 4117978 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
W0410 05:55:44.415000 4117978 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0410 05:55:44.415000 4117978 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
[Rank 0] Using device: cuda:0
Training started at: 2025-04-10 05:55:57.910387
s16g21:4117998:4117998 [0] NCCL INFO Bootstrap : Using ib0:172.23.4.220<0>
s16g21:4117998:4117998 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g21:4117998:4117998 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g21:4117998:4117998 [0] NCCL INFO NET/Plugin: Using internal network plugin.
s16g21:4117998:4117998 [0] NCCL INFO cudaDriverVersion 12000
NCCL version 2.21.5+cuda12.4
s16g21:4117998:4118092 [0] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.220<0>
s16g21:4117998:4118092 [0] NCCL INFO Using non-device net plugin version 0
s16g21:4117998:4118092 [0] NCCL INFO Using network IB
s16g21:4117999:4117999 [1] NCCL INFO cudaDriverVersion 12000
s16g21:4117999:4117999 [1] NCCL INFO Bootstrap : Using ib0:172.23.4.220<0>
s16g21:4117999:4117999 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g21:4117999:4117999 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g21:4117999:4117999 [1] NCCL INFO NET/Plugin: Using internal network plugin.
s16g21:4117999:4118095 [1] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.220<0>
s16g21:4117999:4118095 [1] NCCL INFO Using non-device net plugin version 0
s16g21:4117999:4118095 [1] NCCL INFO Using network IB
s16g21:4117998:4118092 [0] NCCL INFO ncclCommInitRank comm 0x77a743e0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 26000 commId 0x1104c4ba5c01a9d6 - Init START
s16g21:4117999:4118095 [1] NCCL INFO ncclCommInitRank comm 0xa75022c0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId a6000 commId 0x1104c4ba5c01a9d6 - Init START
s16g21:4117999:4118095 [1] NCCL INFO Setting affinity for GPU 1 to ff,00000000
s16g21:4117998:4118092 [0] NCCL INFO Setting affinity for GPU 0 to ff
s16g21:4117999:4118095 [1] NCCL INFO comm 0xa75022c0 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
s16g21:4117998:4118092 [0] NCCL INFO comm 0x77a743e0 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
s16g21:4117999:4118095 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1
s16g21:4117999:4118095 [1] NCCL INFO P2P Chunksize set to 524288
s16g21:4117998:4118092 [0] NCCL INFO Channel 00/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 01/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 02/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 03/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 04/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 05/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 06/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Channel 07/08 :    0   1
s16g21:4117998:4118092 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1
s16g21:4117998:4118092 [0] NCCL INFO P2P Chunksize set to 524288
s16g21:4117998:4118092 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117998:4118092 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g21:4117999:4118095 [1] NCCL INFO Connected all rings
s16g21:4117999:4118095 [1] NCCL INFO Connected all trees
s16g21:4117999:4118095 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g21:4117999:4118095 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g21:4117998:4118092 [0] NCCL INFO Connected all rings
s16g21:4117998:4118092 [0] NCCL INFO Connected all trees
s16g21:4117998:4118092 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g21:4117998:4118092 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g21:4117999:4118095 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g21:4117999:4118095 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g21:4117999:4118095 [1] NCCL INFO ncclCommInitRank comm 0xa75022c0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId a6000 commId 0x1104c4ba5c01a9d6 - Init COMPLETE
s16g21:4117998:4118092 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g21:4117998:4118092 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g21:4117998:4118092 [0] NCCL INFO ncclCommInitRank comm 0x77a743e0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 26000 commId 0x1104c4ba5c01a9d6 - Init COMPLETE
s16g21:4117999:4118098 [1] NCCL INFO [Service thread] Connection closed by localRank 1
Training statistics saved to result/202504100555/train_stats.npy
Configuration saved to result/202504100555/config.json
Training ended at: 2025-04-10 08:08:19.400610
Total training time: 2:12:21.490223
s16g21:4117998:4118100 [0] NCCL INFO [Service thread] Connection closed by localRank 0
s16g21:4117999:140208 [1] NCCL INFO comm 0xa75022c0 rank 1 nranks 2 cudaDev 1 busId a6000 - Abort COMPLETE
s16g21:4117998:140209 [0] NCCL INFO comm 0x77a743e0 rank 0 nranks 2 cudaDev 0 busId 26000 - Abort COMPLETE
