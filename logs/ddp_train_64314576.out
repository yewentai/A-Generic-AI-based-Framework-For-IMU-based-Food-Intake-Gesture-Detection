SLURM_JOB_ID: 64314576
SLURM_JOB_USER: vsc37097
SLURM_JOB_ACCOUNT: lp-emedia
SLURM_JOB_NAME: project_h100.slurm
SLURM_CLUSTER_NAME: wice
SLURM_JOB_PARTITION: gpu_h100
SLURM_NNODES: 1
SLURM_NODELIST: s16g09
SLURM_JOB_CPUS_PER_NODE: 16
SLURM_JOB_GPUS: 1,3
Date: Thu Apr 10 22:40:56 CEST 2025
Walltime: 00-03:00:00
========================================================================
W0410 22:41:16.888000 1810873 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] 
W0410 22:41:16.888000 1810873 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
W0410 22:41:16.888000 1810873 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0410 22:41:16.888000 1810873 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
[Rank 0] Using device: cuda:0
Training started at: 2025-04-10 22:41:34.815688
s16g09:1810894:1810894 [0] NCCL INFO Bootstrap : Using ib0:172.23.4.213<0>
s16g09:1810894:1810894 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g09:1810894:1810894 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g09:1810894:1810894 [0] NCCL INFO NET/Plugin: Using internal network plugin.
s16g09:1810894:1810894 [0] NCCL INFO cudaDriverVersion 12000
NCCL version 2.21.5+cuda12.4
s16g09:1810894:1811228 [0] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.213<0>
s16g09:1810894:1811228 [0] NCCL INFO Using non-device net plugin version 0
s16g09:1810894:1811228 [0] NCCL INFO Using network IB
s16g09:1810895:1810895 [1] NCCL INFO cudaDriverVersion 12000
s16g09:1810895:1810895 [1] NCCL INFO Bootstrap : Using ib0:172.23.4.213<0>
s16g09:1810895:1810895 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g09:1810895:1810895 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g09:1810895:1810895 [1] NCCL INFO NET/Plugin: Using internal network plugin.
s16g09:1810895:1811231 [1] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.213<0>
s16g09:1810895:1811231 [1] NCCL INFO Using non-device net plugin version 0
s16g09:1810895:1811231 [1] NCCL INFO Using network IB
s16g09:1810895:1811231 [1] NCCL INFO ncclCommInitRank comm 0xa7ad7b40 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId c6000 commId 0xf4972b21c4c1307b - Init START
s16g09:1810894:1811228 [0] NCCL INFO ncclCommInitRank comm 0x74eb4a00 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 46000 commId 0xf4972b21c4c1307b - Init START
s16g09:1810894:1811228 [0] NCCL INFO Setting affinity for GPU 0 to ff0000
s16g09:1810895:1811231 [1] NCCL INFO Setting affinity for GPU 1 to ff0000,00000000
s16g09:1810895:1811231 [1] NCCL INFO comm 0xa7ad7b40 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
s16g09:1810895:1811231 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1
s16g09:1810894:1811228 [0] NCCL INFO comm 0x74eb4a00 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
s16g09:1810895:1811231 [1] NCCL INFO P2P Chunksize set to 524288
s16g09:1810894:1811228 [0] NCCL INFO Channel 00/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 01/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 02/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 03/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 04/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 05/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 06/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Channel 07/08 :    0   1
s16g09:1810894:1811228 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1
s16g09:1810894:1811228 [0] NCCL INFO P2P Chunksize set to 524288
s16g09:1810895:1811231 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g09:1810894:1811228 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g09:1810895:1811231 [1] NCCL INFO Connected all rings
s16g09:1810894:1811228 [0] NCCL INFO Connected all rings
s16g09:1810895:1811231 [1] NCCL INFO Connected all trees
s16g09:1810894:1811228 [0] NCCL INFO Connected all trees
s16g09:1810895:1811231 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g09:1810895:1811231 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g09:1810894:1811228 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g09:1810894:1811228 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g09:1810895:1811231 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g09:1810895:1811231 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g09:1810895:1811231 [1] NCCL INFO ncclCommInitRank comm 0xa7ad7b40 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId c6000 commId 0xf4972b21c4c1307b - Init COMPLETE
s16g09:1810894:1811228 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g09:1810894:1811228 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g09:1810894:1811228 [0] NCCL INFO ncclCommInitRank comm 0x74eb4a00 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 46000 commId 0xf4972b21c4c1307b - Init COMPLETE
s16g09:1810895:1811234 [1] NCCL INFO [Service thread] Connection closed by localRank 1
Training statistics saved to result/202504102241/train_stats.npy
Configuration saved to result/202504102241/config.json
Training ended at: 2025-04-11 00:45:56.619994
Total training time: 2:04:21.804306
s16g09:1810894:1811235 [0] NCCL INFO [Service thread] Connection closed by localRank 0
s16g09:1810895:1918192 [1] NCCL INFO comm 0xa7ad7b40 rank 1 nranks 2 cudaDev 1 busId c6000 - Abort COMPLETE
s16g09:1810894:1918193 [0] NCCL INFO comm 0x74eb4a00 rank 0 nranks 2 cudaDev 0 busId 46000 - Abort COMPLETE
