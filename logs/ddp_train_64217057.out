SLURM_JOB_ID: 64217057
SLURM_JOB_USER: vsc37097
SLURM_JOB_ACCOUNT: lp-emedia
SLURM_JOB_NAME: project_h100.slurm
SLURM_CLUSTER_NAME: wice
SLURM_JOB_PARTITION: gpu_h100
SLURM_NNODES: 1
SLURM_NODELIST: s16g15
SLURM_JOB_CPUS_PER_NODE: 16
SLURM_JOB_GPUS: 0,1,2,3
Date: Tue Apr  1 01:10:29 CEST 2025
Walltime: 01-00:00:00
========================================================================
W0401 01:10:35.049000 3980514 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] 
W0401 01:10:35.049000 3980514 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
W0401 01:10:35.049000 3980514 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0401 01:10:35.049000 3980514 /vsc-hard-mounts/leuven-data/370/vsc37097/miniconda3/envs/torch/lib/python3.10/site-packages/torch/distributed/run.py:793] *****************************************
[Rank 0] Using device: cuda:0
Training started at: 2025-04-01 01:10:42.629098
s16g15:3980531:3980531 [0] NCCL INFO Bootstrap : Using ib0:172.23.4.215<0>
s16g15:3980531:3980531 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g15:3980531:3980531 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g15:3980531:3980531 [0] NCCL INFO NET/Plugin: Using internal network plugin.
s16g15:3980531:3980531 [0] NCCL INFO cudaDriverVersion 12000
NCCL version 2.21.5+cuda12.4
s16g15:3980531:3980564 [0] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.215<0>
s16g15:3980531:3980564 [0] NCCL INFO Using non-device net plugin version 0
s16g15:3980531:3980564 [0] NCCL INFO Using network IB
s16g15:3980532:3980532 [1] NCCL INFO cudaDriverVersion 12000
s16g15:3980532:3980532 [1] NCCL INFO Bootstrap : Using ib0:172.23.4.215<0>
s16g15:3980532:3980532 [1] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)
s16g15:3980532:3980532 [1] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so
s16g15:3980532:3980532 [1] NCCL INFO NET/Plugin: Using internal network plugin.
s16g15:3980532:3980570 [1] NCCL INFO NET/IB : Using [0]={[0] mlx5_0:1/IB, [1] mlx5_1:1/IB} [RO]; OOB ib0:172.23.4.215<0>
s16g15:3980532:3980570 [1] NCCL INFO Using non-device net plugin version 0
s16g15:3980532:3980570 [1] NCCL INFO Using network IB
s16g15:3980532:3980570 [1] NCCL INFO ncclCommInitRank comm 0xa80761c0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 46000 commId 0xe1572706a33dbd25 - Init START
s16g15:3980531:3980564 [0] NCCL INFO ncclCommInitRank comm 0x79130220 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 26000 commId 0xe1572706a33dbd25 - Init START
s16g15:3980531:3980564 [0] NCCL INFO Setting affinity for GPU 0 to ff
s16g15:3980532:3980570 [1] NCCL INFO Setting affinity for GPU 1 to ff
s16g15:3980531:3980564 [0] NCCL INFO comm 0x79130220 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
s16g15:3980532:3980570 [1] NCCL INFO comm 0xa80761c0 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
s16g15:3980531:3980564 [0] NCCL INFO Channel 00/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 01/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 02/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 03/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 04/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 05/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 06/08 :    0   1
s16g15:3980531:3980564 [0] NCCL INFO Channel 07/08 :    0   1
s16g15:3980532:3980570 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] 0/-1/-1->1->-1 [3] 0/-1/-1->1->-1 [4] -1/-1/-1->1->0 [5] -1/-1/-1->1->0 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1
s16g15:3980531:3980564 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] -1/-1/-1->0->1 [3] -1/-1/-1->0->1 [4] 1/-1/-1->0->-1 [5] 1/-1/-1->0->-1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1
s16g15:3980532:3980570 [1] NCCL INFO P2P Chunksize set to 524288
s16g15:3980531:3980564 [0] NCCL INFO P2P Chunksize set to 524288
s16g15:3980531:3980564 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980531:3980564 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
s16g15:3980532:3980570 [1] NCCL INFO Connected all rings
s16g15:3980531:3980564 [0] NCCL INFO Connected all rings
s16g15:3980532:3980570 [1] NCCL INFO Connected all trees
s16g15:3980531:3980564 [0] NCCL INFO Connected all trees
s16g15:3980532:3980570 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g15:3980532:3980570 [1] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g15:3980531:3980564 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
s16g15:3980531:3980564 [0] NCCL INFO 8 coll channels, 8 collnet channels, 0 nvls channels, 8 p2p channels, 8 p2p channels per peer
s16g15:3980532:3980570 [1] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g15:3980531:3980564 [0] NCCL INFO TUNER/Plugin: Plugin load returned 11 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so
s16g15:3980532:3980570 [1] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g15:3980531:3980564 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.
s16g15:3980532:3980570 [1] NCCL INFO ncclCommInitRank comm 0xa80761c0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 46000 commId 0xe1572706a33dbd25 - Init COMPLETE
s16g15:3980531:3980564 [0] NCCL INFO ncclCommInitRank comm 0x79130220 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 26000 commId 0xe1572706a33dbd25 - Init COMPLETE
s16g15:3980532:3980574 [1] NCCL INFO [Service thread] Connection closed by localRank 1
Training statistics saved to result/202504010110/train_stats.npy
Configuration saved to result/202504010110/config.json
Training ended at: 2025-04-01 05:00:22.931268
Total training time: 3:49:40.302170
s16g15:3980531:3980573 [0] NCCL INFO [Service thread] Connection closed by localRank 0
s16g15:3980532:4022154 [1] NCCL INFO comm 0xa80761c0 rank 1 nranks 2 cudaDev 1 busId 46000 - Abort COMPLETE
s16g15:3980531:4022155 [0] NCCL INFO comm 0x79130220 rank 0 nranks 2 cudaDev 0 busId 26000 - Abort COMPLETE
